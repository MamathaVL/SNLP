{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)NLP Lab1 Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "#Task1 - Download\n",
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task2 import brown Corpus and accessing data\n",
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161192\n"
     ]
    }
   ],
   "source": [
    "#Size of brown corpus\n",
    "print(len(brown.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Now', 'that', 'he', 'knew', 'himself', 'to', 'be', 'self', 'he', 'was', 'free', 'to', 'grok', 'ever', 'closer', 'to', 'his', 'brothers', ',', 'merge']\n"
     ]
    }
   ],
   "source": [
    "#Accesing first 20 words from brown corpus with categories 'science_fiction'\n",
    "print(brown.words(categories='science_fiction')[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Now that he knew himself to be self he was free to grok ever closer to his brothers , merge'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting list to string using join() method\n",
    "' '.join(brown.words(categories='science_fiction')[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Now', 'that', 'he', 'knew', 'himself', 'to', 'be', 'self', 'he', 'was', 'free', 'to', 'grok', 'ever', 'closer', 'to', 'his', 'brothers', ',', 'merge', 'without', 'let', '.']\n",
      "[\"Self's\", 'integrity', 'was', 'and', 'is', 'and', 'ever', 'had', 'been', '.']\n",
      "['Mike', 'stopped', 'to', 'cherish', 'all', 'his', 'brother', 'selves', ',', 'the', 'many', 'threes-fulfilled', 'on', 'Mars', ',', 'corporate', 'and', 'discorporate', ',', 'the', 'precious', 'few', 'on', 'Earth', '--', 'the', 'unknown', 'powers', 'of', 'three', 'on', 'Earth', 'that', 'would', 'be', 'his', 'to', 'merge', 'with', 'and', 'cherish', 'now', 'that', 'at', 'last', 'long', 'waiting', 'he', 'grokked', 'and', 'cherished', 'himself', '.']\n"
     ]
    }
   ],
   "source": [
    "#Accessing Sentence from brown corpus with categories 'science_fiction' through .sents() method\n",
    "print(brown.sents(categories='science_fiction')[0])\n",
    "print(brown.sents(categories='science_fiction')[1])\n",
    "print(brown.sents(categories='science_fiction')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brown corpus with categories science_fiction 14470 948\n"
     ]
    }
   ],
   "source": [
    "#Length of brown corpus with categories science_fiction in terms of words and sentence count\n",
    "print('brown corpus with categories science_fiction', len(brown.words(categories='science_fiction')), len(brown.sents(categories='science_fiction')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building word frequency distribution for the entire brown corpus\n",
    "inaug_freq = nltk.FreqDist(brown.words())\n",
    "inaug_freq.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inaugural Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-Adams.txt',\n",
       " '1829-Jackson.txt',\n",
       " '1833-Jackson.txt',\n",
       " '1837-VanBuren.txt',\n",
       " '1841-Harrison.txt',\n",
       " '1845-Polk.txt',\n",
       " '1849-Taylor.txt',\n",
       " '1853-Pierce.txt',\n",
       " '1857-Buchanan.txt',\n",
       " '1861-Lincoln.txt',\n",
       " '1865-Lincoln.txt',\n",
       " '1869-Grant.txt',\n",
       " '1873-Grant.txt',\n",
       " '1877-Hayes.txt',\n",
       " '1881-Garfield.txt',\n",
       " '1885-Cleveland.txt',\n",
       " '1889-Harrison.txt',\n",
       " '1893-Cleveland.txt',\n",
       " '1897-McKinley.txt',\n",
       " '1901-McKinley.txt',\n",
       " '1905-Roosevelt.txt',\n",
       " '1909-Taft.txt',\n",
       " '1913-Wilson.txt',\n",
       " '1917-Wilson.txt',\n",
       " '1921-Harding.txt',\n",
       " '1925-Coolidge.txt',\n",
       " '1929-Hoover.txt',\n",
       " '1933-Roosevelt.txt',\n",
       " '1937-Roosevelt.txt',\n",
       " '1941-Roosevelt.txt',\n",
       " '1945-Roosevelt.txt',\n",
       " '1949-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1965-Johnson.txt',\n",
       " '1969-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1977-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '2001-Bush.txt',\n",
       " '2005-Bush.txt',\n",
       " '2009-Obama.txt',\n",
       " '2013-Obama.txt',\n",
       " '2017-Trump.txt']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task3 Import Inaugural corpus and access data\n",
    "\n",
    "from nltk.corpus import inaugural\n",
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149797\n"
     ]
    }
   ],
   "source": [
    "# Inaugral Corpus size in number of words\n",
    "print(len(inaugural.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thank',\n",
       " 'you',\n",
       " '.',\n",
       " 'Thank',\n",
       " 'you',\n",
       " 'so',\n",
       " 'much',\n",
       " '.',\n",
       " 'Vice',\n",
       " 'President',\n",
       " 'Biden',\n",
       " ',',\n",
       " 'Mr',\n",
       " '.',\n",
       " 'Chief',\n",
       " 'Justice',\n",
       " ',',\n",
       " 'Members',\n",
       " 'of',\n",
       " 'the']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accesing first 20 words from Obama 2013 speech txt file\n",
    "inaugural.words(fileids ='2013-Obama.txt')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thank', 'you', '.']\n",
      "['Thank', 'you', 'so', 'much', '.']\n",
      "['Vice', 'President', 'Biden', ',', 'Mr', '.', 'Chief', 'Justice', ',', 'Members', 'of', 'the', 'United', 'States', 'Congress', ',', 'distinguished', 'guests', ',', 'and', 'fellow', 'citizens', ':']\n",
      "['Each', 'time', 'we', 'gather', 'to', 'inaugurate', 'a', 'President', 'we', 'bear', 'witness', 'to', 'the', 'enduring', 'strength', 'of', 'our', 'Constitution', '.']\n"
     ]
    }
   ],
   "source": [
    "#NLTK segments sentences  which are accessed through .sents()\n",
    "print(inaugural.sents('2013-Obama.txt')[0]) #First sentence\n",
    "print(inaugural.sents('2013-Obama.txt')[1]) #second sentence\n",
    "print(inaugural.sents('2013-Obama.txt')[2]) #third sentence\n",
    "print(inaugural.sents('2013-Obama.txt')[3]) #Fourth sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-Obama.txt: 2369 92\n"
     ]
    }
   ],
   "source": [
    "#Length of the speech in terms of words and sentence count\n",
    "print('2013-Obama.txt:', len(inaugural.words('2013-Obama.txt')), len(inaugural.sents('2013-Obama.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1538 1789-Washington.txt\n",
      "147 1793-Washington.txt\n",
      "2585 1797-Adams.txt\n",
      "1935 1801-Jefferson.txt\n",
      "2384 1805-Jefferson.txt\n",
      "1265 1809-Madison.txt\n",
      "1304 1813-Madison.txt\n",
      "3693 1817-Monroe.txt\n",
      "4909 1821-Monroe.txt\n",
      "3150 1825-Adams.txt\n",
      "1208 1829-Jackson.txt\n",
      "1267 1833-Jackson.txt\n",
      "4171 1837-VanBuren.txt\n",
      "9165 1841-Harrison.txt\n",
      "5196 1845-Polk.txt\n",
      "1182 1849-Taylor.txt\n",
      "3657 1853-Pierce.txt\n",
      "3098 1857-Buchanan.txt\n",
      "4005 1861-Lincoln.txt\n",
      "785 1865-Lincoln.txt\n",
      "1239 1869-Grant.txt\n",
      "1478 1873-Grant.txt\n",
      "2724 1877-Hayes.txt\n",
      "3239 1881-Garfield.txt\n",
      "1828 1885-Cleveland.txt\n",
      "4750 1889-Harrison.txt\n",
      "2153 1893-Cleveland.txt\n",
      "4371 1897-McKinley.txt\n",
      "2450 1901-McKinley.txt\n",
      "1091 1905-Roosevelt.txt\n",
      "5846 1909-Taft.txt\n",
      "1905 1913-Wilson.txt\n",
      "1656 1917-Wilson.txt\n",
      "3756 1921-Harding.txt\n",
      "4442 1925-Coolidge.txt\n",
      "3890 1929-Hoover.txt\n",
      "2063 1933-Roosevelt.txt\n",
      "2019 1937-Roosevelt.txt\n",
      "1536 1941-Roosevelt.txt\n",
      "637 1945-Roosevelt.txt\n",
      "2528 1949-Truman.txt\n",
      "2775 1953-Eisenhower.txt\n",
      "1917 1957-Eisenhower.txt\n",
      "1546 1961-Kennedy.txt\n",
      "1715 1965-Johnson.txt\n",
      "2425 1969-Nixon.txt\n",
      "2028 1973-Nixon.txt\n",
      "1380 1977-Carter.txt\n",
      "2801 1981-Reagan.txt\n",
      "2946 1985-Reagan.txt\n",
      "2713 1989-Bush.txt\n",
      "1855 1993-Clinton.txt\n",
      "2462 1997-Clinton.txt\n",
      "1825 2001-Bush.txt\n",
      "2376 2005-Bush.txt\n",
      "2726 2009-Obama.txt\n",
      "2369 2013-Obama.txt\n",
      "1693 2017-Trump.txt\n"
     ]
    }
   ],
   "source": [
    "# print word count of each speech txt file\n",
    "for f in inaugural.fileids():\n",
    "    print(len(inaugural.words(f)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 9446),\n",
       " ('of', 7087),\n",
       " (',', 7045),\n",
       " ('and', 5146),\n",
       " ('.', 4856),\n",
       " ('to', 4414),\n",
       " ('in', 2561),\n",
       " ('a', 2184),\n",
       " ('our', 2021),\n",
       " ('that', 1748),\n",
       " ('be', 1483),\n",
       " ('is', 1448),\n",
       " ('we', 1211),\n",
       " ('for', 1110),\n",
       " ('by', 1053),\n",
       " ('it', 1028),\n",
       " ('have', 1008),\n",
       " ('which', 1006),\n",
       " ('not', 949),\n",
       " ('will', 909),\n",
       " ('with', 906),\n",
       " ('as', 904),\n",
       " ('I', 838),\n",
       " ('are', 808),\n",
       " ('all', 784),\n",
       " ('their', 733),\n",
       " ('this', 720),\n",
       " ('The', 629),\n",
       " ('has', 621),\n",
       " ('people', 580),\n",
       " (';', 563),\n",
       " ('its', 561),\n",
       " ('or', 554),\n",
       " ('from', 540),\n",
       " ('We', 532),\n",
       " ('on', 509),\n",
       " ('but', 497),\n",
       " ('been', 488),\n",
       " ('us', 478),\n",
       " ('can', 465),\n",
       " ('my', 450),\n",
       " ('no', 416),\n",
       " ('an', 386),\n",
       " ('who', 365),\n",
       " ('must', 365),\n",
       " ('upon', 365),\n",
       " ('--', 363),\n",
       " ('so', 362),\n",
       " ('It', 361),\n",
       " ('they', 352)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building word frequency distribution for the entire corpus\n",
    "inaug_freq = nltk.FreqDist(inaugural.words())\n",
    "inaug_freq.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webtext Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firefox.txt Cookie Manager: \"Don't allow sites that set removed cookies to set future cookies\" should stay check\n",
      "grail.txt SCENE 1: [wind] [clop clop clop] \n",
      "KING ARTHUR: Whoa there!  [clop clop clop] \n",
      "SOLDIER #1: Halt!  Who\n",
      "overheard.txt White guy: So, do you have any plans for this evening?\n",
      "Asian girl: Yeah, being angry!\n",
      "White guy: Oh,\n",
      "pirates.txt PIRATES OF THE CARRIBEAN: DEAD MAN'S CHEST, by Ted Elliott & Terry Rossio\n",
      "[view looking straight dow\n",
      "singles.txt 25 SEXY MALE, seeks attrac older single lady, for discreet encounters.\n",
      "35YO Security Guard, seeking \n",
      "wine.txt Lovely delicate, fragrant Rhone wine. Polished leather and strawberries. Perhaps a bit dilute, but g\n"
     ]
    }
   ],
   "source": [
    "#Task 4 Import webtext corpus and access data\n",
    "from nltk.corpus import webtext\n",
    "webtext.fileids()\n",
    "\n",
    "for fileid in webtext.fileids():\n",
    "    print(fileid, webtext.raw(fileid)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gutenberg Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task 5 Import gutenberg corpus and access data\n",
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25833"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size of the corpus\n",
    "shakespeare_caesar= gutenberg.words(\"shakespeare-caesar.txt\")\n",
    "len(shakespeare_caesar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Tragedie of Julius Caesar by William Shakespeare 1599]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Enter Flauius, Murellus, and certaine Commoners ouer the Stage.\n",
      "\n",
      "  Flauius. Hence: home you idle Creatures, get you home:\n",
      "Is this a Holiday? What, know you not\n",
      "(Being Mechanicall) you ought not walke\n",
      "Vpon a labouring day, without the signe\n",
      "Of your Profession? Speake, what Trade art thou?\n",
      "  Car. Why Sir, a Carpenter\n",
      "\n",
      "   Mur. Where is thy Leather Apron, and thy Rule?\n",
      "What dost thou with thy best Apparrell on?\n",
      "You sir, what Trade are you?\n",
      "  Cobl. Truely Sir, in respect of a fine Workman, I am\n",
      "but as you would say, a Cobler\n",
      "\n",
      "   Mur. But what Trade art thou? Answer me directly\n",
      "\n",
      "   Cob. A Trade Sir, that I hope I may vse, with a safe\n",
      "Conscience, which is indeed Sir, a Mender of bad soules\n",
      "\n",
      "   Fla. What Trade thou knaue? Thou naughty knaue,\n",
      "what Trade?\n",
      "  Cobl. Nay I beseech you Sir, be not out with me: yet\n",
      "if you be out Sir, I can mend you\n",
      "\n",
      "   Mur. What mean'st thou by that? Mend mee, thou\n",
      "sawcy Fellow?\n"
     ]
    }
   ],
   "source": [
    "#Print the content of austen-emma.txt file from gutenberg corpus\n",
    "print(gutenberg.raw(\"shakespeare-caesar.txt\")[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']']\n",
      "['Actus', 'Primus', '.']\n",
      "['Scoena', 'Prima', '.']\n"
     ]
    }
   ],
   "source": [
    "#Accessing Sentence\n",
    "print(gutenberg.sents('shakespeare-macbeth.txt')[0])#first sentence\n",
    "print(gutenberg.sents('shakespeare-macbeth.txt')[1])#second sentence\n",
    "print(gutenberg.sents('shakespeare-macbeth.txt')[2])#third sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 186091),\n",
       " ('the', 125748),\n",
       " ('and', 78846),\n",
       " ('.', 73746),\n",
       " ('of', 70078),\n",
       " (':', 47406),\n",
       " ('to', 46443),\n",
       " ('a', 32504),\n",
       " ('in', 31959),\n",
       " ('I', 30221),\n",
       " (';', 27329),\n",
       " ('that', 27289),\n",
       " ('he', 22198),\n",
       " ('his', 20585),\n",
       " (\"'\", 19873),\n",
       " ('it', 19734),\n",
       " ('was', 18558),\n",
       " ('for', 16860),\n",
       " ('not', 16834),\n",
       " ('with', 16827),\n",
       " ('And', 16533),\n",
       " ('is', 15944),\n",
       " ('be', 15844),\n",
       " ('\"', 15422),\n",
       " ('you', 14648),\n",
       " ('as', 13335),\n",
       " ('all', 12965),\n",
       " ('him', 12924),\n",
       " ('they', 11536),\n",
       " ('shall', 11456),\n",
       " ('her', 11153),\n",
       " ('them', 10218),\n",
       " ('had', 10177),\n",
       " ('have', 9900),\n",
       " ('s', 9792),\n",
       " ('my', 9580),\n",
       " ('said', 9410),\n",
       " ('me', 9376),\n",
       " ('but', 9252),\n",
       " ('unto', 8953),\n",
       " ('-', 8850),\n",
       " ('from', 8647),\n",
       " ('at', 8642),\n",
       " ('which', 8435),\n",
       " ('on', 8194),\n",
       " ('by', 8012),\n",
       " ('this', 7706),\n",
       " ('The', 7542),\n",
       " ('their', 7516),\n",
       " ('she', 7434)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building word frequency distribution for the entire gutenberg corpus\n",
    "gutenberg_freq = nltk.FreqDist(gutenberg.words())\n",
    "gutenberg_freq.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task5 Frequency Distribution of words in a text\n",
    "import nltk\n",
    "text = '''A fourth approach is harder to intuitively understand, but is inspired by how the brain's machinery works: the artificial neural network approach uses artificial \"neurons\" that can learn by comparing itself to the desired output and altering the strengths of the connections between its internal neurons to \"reinforce\" connections that seemed to be useful'''\n",
    "fd = nltk.FreqDist(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 5, 'to': 4, 'approach': 2, 'is': 2, 'by': 2, 'artificial': 2, 'that': 2, 'connections': 2, 'A': 1, 'fourth': 1, ...})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task6 Conditional Frequency Distribution of words in a text\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "\n",
    "cfd = ConditionalFreqDist((len(word), word) for word in text.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'that': 2, 'uses': 1})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conditional Frequency Distribution of Words with length 4\n",
    "cfd[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'learn': 1})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conditional Frequency Distribution of Words with length 5\n",
    "cfd[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'fourth': 1, 'harder': 1, 'works:': 1, 'neural': 1, 'itself': 1, 'output': 1, 'seemed': 1, 'useful': 1})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conditional Frequency Distribution of Words with length 6\n",
    "cfd[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Distribution and conditional Frequency Distribution of words in text for brown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Text from Corpus - Brown\n",
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access Data with category 'news'\n",
    "text=brown.words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100554"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Length of the Corpus - Brown with category 'news' \n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the content of Corpus - Brown with category 'news'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting List to the string\n",
    "texts = ' '.join([str(item) for item in text ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency Distribution of words in a text\n",
    "import nltk\n",
    "freqdist = nltk.FreqDist(texts.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 5580, ',': 5188, '.': 4030, 'of': 2849, 'and': 2146, 'to': 2116, 'a': 1993, 'in': 1893, 'for': 943, 'The': 806, ...})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the Frequency Distribution of words \n",
    "freqdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conditional Frequency Distribution of words in a text\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "\n",
    "cfd = ConditionalFreqDist((len(word), word) for word in texts.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'that': 802, 'with': 545, 'said': 402, 'will': 389, 'from': 344, 'have': 265, 'Mrs.': 253, 'were': 252, 'this': 250, 'been': 212, ...})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conditional Frequency Distribution of Words with length 4\n",
    "cfd[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'which': 244, 'would': 244, 'their': 219, 'other': 149, 'first': 143, 'about': 136, 'there': 131, 'after': 127, 'years': 102, 'three': 97, ...})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conditional Frequency Distribution of Words with length 5\n",
    "cfd[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'before': 86, 'school': 65, 'should': 59, 'United': 58, 'during': 55, 'Monday': 54, 'people': 52, 'public': 51, 'Sunday': 51, 'Dallas': 49, ...})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conditional Frequency Distribution of Words with length 6\n",
    "cfd[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
